<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>A (very short) introduction to Machine Learning</title>
  <meta name="description" content="  Definition: Machine Learning (ML) is the set of all the techniques and algorithms able to extract knowledge from the data, and use that knowledge to make accurate previsions." />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
  
  <meta property="og:site_name" content="NeuroMath" />
  <meta property="og:title" content="A (very short) introduction to Machine Learning"/>
  
  <meta property="og:description" content="  Definition: Machine Learning (ML) is the set of all the techniques and algorithms able to extract knowledge from the data, and use that knowledge to make accurate previsions." />
  
  <meta property="og:image" content="http://localhost:4000/assets/images/intro_to_ML/header.jpeg" />
  <meta property="og:url" content="http://localhost:4000/jekyll/update/2022/09/26/short_introduction_to_ML.html" >
  <meta property="og:type" content="blog" />
  <meta property="article:published_time" content="2022-09-26T11:00:00+02:00">

  <link rel="canonical" href="http://localhost:4000/jekyll/update/2022/09/26/short_introduction_to_ML.html"/>
  <link rel="shortcut icon" href="/assets/images/favicon.png" type="image/png"/>
  <link rel="stylesheet" href="//brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />
  
  <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <!-- for mathjax support -->
  <!-- 
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(', '\\)'] ],
      processEscapes: true,
    },
    "HTML-CSS" : {
      availableFonts : ["STIX"],
      preferredFont : "STIX",
      webFont : "STIX-Web",
      imageFont : null
    }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
   -->
</head>


  <body>

    <!-- header start -->


  <a href="/" class="logo-readium"><span class="logo" style="background-image: url(/assets/images/df_logo.png)"></span></a>

<!-- header end -->

    <!-- content start -->

    <div class="page-content">
      <div class="wrapper">
        <!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>A (very short) introduction to Machine Learning</title>
  <meta name="description" content="  Definition: Machine Learning (ML) is the set of all the techniques and algorithms able to extract knowledge from the data, and use that knowledge to make accurate previsions." />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
  
  <meta property="og:site_name" content="NeuroMath" />
  <meta property="og:title" content="A (very short) introduction to Machine Learning"/>
  
  <meta property="og:description" content="  Definition: Machine Learning (ML) is the set of all the techniques and algorithms able to extract knowledge from the data, and use that knowledge to make accurate previsions." />
  
  <meta property="og:image" content="http://localhost:4000/assets/images/intro_to_ML/header.jpeg" />
  <meta property="og:url" content="http://localhost:4000/jekyll/update/2022/09/26/short_introduction_to_ML.html" >
  <meta property="og:type" content="blog" />
  <meta property="article:published_time" content="2022-09-26T11:00:00+02:00">

  <link rel="canonical" href="http://localhost:4000/jekyll/update/2022/09/26/short_introduction_to_ML.html"/>
  <link rel="shortcut icon" href="/assets/images/favicon.png" type="image/png"/>
  <link rel="stylesheet" href="//brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />
  
  <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <!-- for mathjax support -->
  <!-- 
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(', '\\)'] ],
      processEscapes: true,
    },
    "HTML-CSS" : {
      availableFonts : ["STIX"],
      preferredFont : "STIX",
      webFont : "STIX-Web",
      imageFont : null
    }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
   -->
</head>

  <body itemscope itemtype="http://schema.org/Article">
    <!-- header start -->


  <a href="/" class="logo-readium"><span class="logo" style="background-image: url(/assets/images/df_logo.png)"></span></a>

<!-- header end -->
    <main class="content" role="main">
      <article class="post">
        
        <div class="article-image">
          <div class="post-image-image" style="background-image: url(/assets/images/intro_to_ML/header.jpeg)">
            Article Image
          </div>
          <div class="post-image-image2" style="background-image: url()">
            Article Image
          </div>
          <div class="post-meta">
            <h1 class="post-title">A (very short) introduction to Machine Learning</h1>
            <div class="cf post-meta-text">
              <div class="author-image" style="background-image: url(/assets/images/author.png)">Blog Logo</div>
              <h4 class="author-name" itemprop="author" itemscope itemtype="http://schema.org/Person">Davide Evangelista</h4>
              on
              <time datetime="2022-09-26 11:00">26 Sep 2022</time>
              <!-- , tagged on <span class="post-tag-">, <a href="/tag/"></a></span> -->
            </div>
            <div style="text-align:center">
              <a href="#topofpage" class="topofpage"><i class="fa fa-angle-down"></i></a>
            </div>
          </div>
        </div>
        
        <section class="post-content">
          <div class="post-reading">
            <span class="post-reading-time"></span> read
          </div>
          <a name="topofpage"></a>
          <blockquote>
  <p><strong><em>Definition:</em></strong> Machine Learning (ML) is the set of all the techniques and algorithms able to extract knowledge from the data, and use that knowledge to make accurate previsions.</p>
</blockquote>

<p>Following the definition, it is clear that a good Machine Learning algorithm is always developed by following some steps:</p>

<ul>
  <li><strong>Understanding:</strong> Understand the task (e.g.  what do we need? what are the informations we are able to collect to answer the question we are asking for?);</li>
  <li><strong>Collection:</strong> Collect a big set of data, containing enough informations to be able to use them to achieve the task above;</li>
  <li><strong>Design:</strong> Design the Machine Learning algorithm, based on the knowledge we have on the studied problem;</li>
  <li><strong>Training:</strong> Train the algorithm on the collected data, trying to minimize the prediction error on the given dataset;</li>
  <li><strong>Tuning:</strong> Eventually tune some parameters of the model (a ML algorithm is usually referred to as <em>model</em>) to improve the predictions;</li>
  <li><strong>Testing:</strong> Test the algorithm on new data, verifying its ability on making predictions;</li>
</ul>

<p>We’re going to investigate each of those steps more deeply in the following.</p>

<h2 id="understanding">Understanding</h2>
<p>Assume we want to solve a given problem. Mathematically, the problem we aim to solve can be modelled as an (unknown) function $f(x)$, taking as input a vector $x \in \mathbb{R}^d$ containing the informations we are able to collect and mapping them (possibly <strong>stocastically</strong>) to the task $y = f(x)$. When this is the case, $x$ is usually called <em>input vector</em> or alternatively <em>feature vector</em>, while $y = f(x)$ is the <em>target</em> (equivalently <em>label</em> or <em>output</em>).</p>

<p><em>Solving</em> the problem means being able to approximate $f(x)$ as good as possible with a model (that we will always indicate as $f_\theta (x)$, $\theta$ being the set of parameters defining it), such that</p>

\[f_\theta(x) \approx f(x) \qquad \forall x \in \mathbb{R}^d\]

<h3 id="question-1-is-it-learnable">Question 1: Is it learnable?</h3>
<p>A problem $y = f(x)$ can be solved by a ML algorithm if and only if there <strong>exists</strong> a relationship between $x$ and $y$. For example, we cannot expect to predict the future weather in a particular position by using informations about the stock price of a particular company. In that situation, the input and the output are clearly <strong>indepdendent</strong>, and there is no change to learning anything from one using the other.</p>

<p>Consequently, the first point in designing a ML algorithm is to understand <em>if</em> there exists a correlation between the input and the output of the given problem. When this is the case, we say that the problem is <strong>learnable</strong>.</p>

<blockquote>
  <p><strong>Machine Learning</strong> is about understanding correlations (patterns).</p>
</blockquote>

<h3 id="question-2-it-is-possible-to-collect-them">Question 2: It is possible to collect them?</h3>
<p>Assume that the problem $y = f(x)$ is learnable. We need to understand if we can physically collect enough data $x$ to be able to understand the relationship between him and its corresponding $y$.</p>

<p>For example, if we want to use ML to make cancer diagnosis on patients, clearly the best way to do that is to use as input the clinical results of any possible medical exam on the patient. Of course, even if this will work well in practice, it is not possible (and expecially not ethic) to test the patient with thousands of exams for a single diagnosis.</p>

<p>Moreover, to train a good ML model, we will need thousands (sometimes milions) of datapoints, and it is not always possible to scale our problem to be able to collect enough data to solve it.</p>

<blockquote>
  <p>Collecting data requires <strong>efficiency</strong> and <strong>scalability</strong> of the problem.</p>
</blockquote>

<h2 id="collection">Collection</h2>
<p>Collecting data is usually the hardest part in the design of a Machine Learning production. In fact, given that our problem $y = f(x)$ is solvable and that it is theoretically possible to collect enough data about it, it is not always that easy in practice.</p>

<p>In particular, some data requires <em>time</em> to be collected (this is an example when working in biological or medical applications), and collect good quality data is hard. Indeed, we indeally want to use a clean dataset, where all the informations are presents, there are no missing values (usually referred to as <code class="language-plaintext highlighter-rouge">NaN</code>) and the informations does not contain noise. Most of the time, this is hopeless, and we will need to develop algorithms to standardize and clean up the data. The set of all those techniques is called <em>data cleaning</em>, and its study is beyond the scope of this course.</p>

<h3 id="kaggle">Kaggle</h3>
<p>Luckily, for most of the tasks you can think of, you can find datasets on internet. For example, websites like <a href="https://www.kaggle.com/">Kaggle</a> and <a href="https://datasetsearch.research.google.com/">Google Datasets</a> can be helpful for that.</p>

<h3 id="data-loading-with-pandas">Data loading with pandas</h3>
<p>At the end of the <a href="/jekyll/update/2022/09/16/introduction_to_python_numpy.html">introductory post</a> we introduced the Python library <code class="language-plaintext highlighter-rouge">pandas</code>, useful to work with data.</p>

<p>In particular, most of the data can be found in the <code class="language-plaintext highlighter-rouge">.csv</code> format, and <code class="language-plaintext highlighter-rouge">pandas</code> contains functions to read <code class="language-plaintext highlighter-rouge">.csv</code> files and work with it. Please refer to the <a href="/jekyll/update/2022/09/16/introduction_to_python_numpy.html">introductory post</a> for more informations about it.</p>

<h3 id="datasets-and-numpy-arrays">Datasets and numpy arrays</h3>
<p><code class="language-plaintext highlighter-rouge">.csv</code> datasets are great. Working with them, we will always have all the informations correctly labeled and in-place. Unfortunately, from a mathematical point of view, this is a really sub-optimal way of working with data. In particular, working with strings is usually a pain and it is mandatory to setup an algorithm converting strings into numbers (an <em>encoding</em> algorithm), and columns and rows names are unnecessary while designing learning algorithms.</p>

<p>Consequently, we will always convert datasets into matrices (into the form of <code class="language-plaintext highlighter-rouge">numpy</code> arrays), before starting working with them. This is performed by two successive steps:</p>

<ol>
  <li>Encoding strings into numbers.</li>
  <li>Converting the resulting dataset into a numpy array.</li>
</ol>

<hr />

<p>The idea of encoding algorithms is that in a dataset, the set of possible values a string can have is limited (e.g. in a dataset containing weather informations, we can say that the climate is {raining, sunny, cloudy, snowy}, thus we have only 4 possible values for the string). Consequently, the idea is to consider each one of the possible values as a <strong>class</strong>.</p>

<p>Assume our dataset has $K$ classes for a specific feature, let’s say ${ C_1, C_2, \dots, C_K }$ is the set of all the classes. Then, there are two mainly used encoding algorithms:</p>

<ul>
  <li><strong>Integer encoding:</strong> Each class $C_k$, $k = 1, \dots, K$, is simply mapped to its index $k$ (<em>Warning:</em> this method creates a usually unintended ordering on the classes, i.e. $C_k \leq C_j$ if $i &lt; j$). In Python, this function is implemented by the function <code class="language-plaintext highlighter-rouge">sklearn.preprocessing.LabelEncoder()</code> from <code class="language-plaintext highlighter-rouge">sklearn</code>, a famous library performing ML operations.</li>
  <li><strong>One-hot-encoding:</strong> Each class $C_k$ is mapped to the $K$-dimensional canonical vector $e_k$, where $e_i$ is a vector of all zeros exept for the $k$-th element, which is a 1 (<em>Advantages:</em> this way we can define the concept of being partially in a class). In Python, this function is implemented by the function <code class="language-plaintext highlighter-rouge">sklearn.preprocessing.OneHotEncoder()</code>.</li>
</ul>

<hr />

<p>After the encoding step, the dataset is simply converted to a numpy array with the <code class="language-plaintext highlighter-rouge">np.array()</code> function.</p>

<p>The result of this procedure is a matrix</p>

\[X = [ x^1 \quad x^2 \quad \dots \quad x^N ]^T \in \mathbb{R}^{N \times d}\]

<p>where each row $x^i \in \mathbb{R}^d$ represents a datapoint with $d$ features and $N$ is the number of datapoints. The corresponding labels $y^i = f(x^i)$ for each datapoint are collected into a vector $Y = [y^1, y^2, \dots, y^N]^T \in \mathbb{R}^N$</p>

<h2 id="design">Design</h2>
<p>Designing a ML model is an hard</p>

<h2 id="training">Training</h2>

<h2 id="tuning">Tuning</h2>

<h2 id="testing">Testing</h2>

        </section>
        <footer class="post-footer">
          <section class="share">
            
          </section>
        </footer>
        <div class="bottom-teaser cf">
          <div class="isLeft">
            <h5 class="index-headline featured"><span>Written by</span></h5>
            <section class="author">
              <div class="author-image" style="background-image: url(/assets/images/author.png)">Blog Logo</div>
              <h4>Davide Evangelista</h4>
              <p class="bio"></p>
              <hr>
              <p class="published">Published <time datetime="2022-09-26 11:00">26 Sep 2022</time></p>
            </section>
          </div>
          
          <div class="isRight">
            <h5 class="index-headline featured"><span>Supported by</span></h5>
            <footer class="site-footer">
              <section class="poweredby">Proudly published with <a href="http://jekyllrb.com"> Jekyll</a></section>
              <div class="inner">
                <section class="copyright">All content copyright <a href="/">Davide Evangelista</a> &copy; 2022<br>All rights reserved.</section>
              </div>
            </footer>
          </div>
        </div>
        
      </article>
    </main>
    <div class="bottom-closer">
      <div class="background-closer-image"  style="background-image: url(/assets/images/cA4aKEIPQrerBnp1yGHv_IMG_9534-3-2.jpg)">
        Image
      </div>
      <div class="inner">
        <h1 class="blog-title">NeuroMath</h1>
        <h2 class="blog-description">A blog about Mathematics and Neural Networks.
</h2>
        <a href=/ class="btn">Back to Overview</a>
      </div>
    </div>
    <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    
      $window.on('scroll', function() {
        var top = $window.scrollTop();

        if (top < 0 || top > 1500) { return; }
        $image
          .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
          .css('opacity', 1-Math.max(top/700, 0));
      });
      $window.trigger('scroll');

      var height = $('.article-image').height();
      $('.post-content').css('padding-top', height + 'px');

      $('a[href*=#]:not([href=#])').click(function() {
        if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
         && location.hostname == this.hostname) {
          var target = $(this.hash);
          target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
          if (target.length) {
            $('html,body').animate({ scrollTop: target.offset().top }, 500);
            return false;
          }
        }
      });

  });
}(jQuery));
</script>


  </body>
</html>
      </div>
    </div>

    <!-- content end -->

    <!-- footer start -->

<footer class="site-footer">
    <div class="inner">
         <section class="copyright">All content copyright <a href="mailto:">Davide Evangelista</a> &copy; 2022 &bull; All rights reserved.</section>
    </div>
</footer>

<!-- footer end -->
    <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    
      $window.on('scroll', function() {
        var top = $window.scrollTop();

        if (top < 0 || top > 1500) { return; }
        $image
          .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
          .css('opacity', 1-Math.max(top/700, 0));
      });
      $window.trigger('scroll');

      var height = $('.article-image').height();
      $('.post-content').css('padding-top', height + 'px');

      $('a[href*=#]:not([href=#])').click(function() {
        if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
         && location.hostname == this.hostname) {
          var target = $(this.hash);
          target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
          if (target.length) {
            $('html,body').animate({ scrollTop: target.offset().top }, 500);
            return false;
          }
        }
      });

  });
}(jQuery));
</script>



  </body>

</html>

<script src=”https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=”MathJax-script” async src=”https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
